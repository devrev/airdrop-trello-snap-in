{
    "1.1": {
        "functional_requirement": "- Implement The Function that only checks if The Function can be invoked.",
        "folder_name": "conformance_tests/function_invocation_check"
    },
    "1.2": {
        "functional_requirement": "- Implement The Function called \"test_external_sync_units\" (The External Sync Units Test Function) that provides a test of the 'external sync units' part of the extraction workflow as described in the resource `[resource]external-sync-units-extraction.mdx`.\n  - If \"event_type\" equals \"EXTRACTION_EXTERNAL_SYNC_UNITS_START\", The External Sync Units Test Function should:\n    - Only emit event \"EXTRACTION_EXTERNAL_SYNC_UNITS_DONE\".",
        "folder_name": "conformance_tests/external_sync_units_event_handling",
        "acceptance_tests": [
            "- Test The Function using the resource `[resource]external_sync_unit_check.json`. Test is successful if The Callback Server receives from DevRev an event with \"event_type\" that equals \"EXTRACTION_EXTERNAL_SYNC_UNITS_DONE\". The test must not send the event directly to The Callback Server."
        ]
    },
    "1.3": {
        "functional_requirement": "- Implement The Function called \"data_extraction_check\" (The Data Extraction Check Function) that provides a test of the 'data extraction' part of the extraction workflow as described in the resource `[resource]data-extraction.md`. The Data Extraction Check Function should:\n  - if \"event_type\" equals \"EXTRACTION_DATA_START\" or \"EXTRACTION_ATTACHMENTS_CONTINUE\", The Data Extraction Check Function should:\n    - Initialize a single repo \"users\"\n    - normalize the users data using The Normalization Function\n    - push the normalized users data to The DevRev Servers\n    - Emit event \"EXTRACTION_DATA_DONE\".\n    - Note: The Data Extraction Check Function should be simplified and should disregard all other details.",
        "folder_name": "conformance_tests/data_extraction_check_tests",
        "acceptance_tests": [
            "- Test The Function using the resource `[resource]data_extraction_check.json`. Test is successful if The Callback Server receives from DevRev an event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\". The test must not send the event directly to The Callback Server."
        ]
    },
    "2.1.1": {
        "functional_requirement": "- Implement The Function \"check_authentication\" that provides a check if authentication with The API works. Authentication should be checked by making a request to the endpoint \"/members/{id}\", and providing \"me\" as the value of the \"id\" parameter.",
        "folder_name": "conformance_tests/authentication_check_function_tests",
        "acceptance_tests": [
            "- Test the rate limiting of The Function \"check_authentication\" with the following flow:\n  - Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Invoke The Function \"check_authentication\" with valid credentials and all required parameters.\n  - Expect: `status_code = 429`.\n  - Expect: `api_delay > 0` and `api_delay <= 3`. If api_delay is bigger than 3, assume the problem is that we did not calculate the api_delay correctly in The Implementation Code.\n  - Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.1.2": {
        "functional_requirement": "- Implement The Function \"fetch_boards\" that uses The API to fetch The List of Boards (The Fetched Boards) using the endpoint \"/members/{id}/boards\".",
        "folder_name": "conformance_tests/fetch_boards_api_tests",
        "acceptance_tests": [
            "- Test the function \"fetch_boards. Expect to exist a board with the name \"SaaS connectors\" in the result of The Function.",
            "- Test the rate limiting of The Function \"fetch_boards\" with the following flow:\n  - Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Invoke The Function \"fetch_boards\" with valid credentials and all required parameters.\n  - Expect: `status_code = 429`.\n  - Expect: `api_delay > 0` and `api_delay <= 3`. If api_delay is bigger than 3, assume the problem is that we did not calculate the api_delay correctly in The Implementation Code.\n  - Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.1.3": {
        "functional_requirement": "- Implement The Function \"fetch_organization_members\" that uses The API to fetch The List of Users of The Organization (The Fetched Users) using the endpoint \"/organizations/{id}/members\". The Organization ID should be provided in `event[\"payload\"][\"connection_data\"][\"org_id\"]`.",
        "folder_name": "conformance_tests/fetch_organization_members_api_tests",
        "acceptance_tests": [
            "- Test the rate limiting of The Function \"fetch_organization_members\" with the following flow:\n  - Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Invoke The Function \"fetch_organization_members\" with valid credentials and all required parameters.\n  - Expect: `status_code = 429`.\n  - Expect: `api_delay > 0` and `api_delay <= 3`. If api_delay is bigger than 3, assume the problem is that we did not calculate the api_delay correctly in The Implementation Code.\n  - Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.1.4": {
        "functional_requirement": "- Implement The Function \"fetch_board_cards\" that uses The API to fetch The Fetched Cards for a given board using the endpoint \"/boards/{id}/cards\".\n  - The Board ID should be provided in `event[\"payload\"][\"event_context\"][\"external_sync_unit_id\"]`\n  - The following pagination parameters should be supported:\n    - \"limit\" (required, integer)\n    - \"before\" (optional, string)\n  - \"limit\" and \"before\" should be provided in `event[\"input_data\"][\"global_values\"][\"limit\"]` and `event[\"input_data\"][\"global_values\"][\"before\"]`.\n  - Endpoint \"/boards/{id}/cards\" should be called with query param `attachments` set to `true`.",
        "folder_name": "conformance_tests/fetch_board_cards_api_tests",
        "acceptance_tests": [
            "- Test The Function \"fetch_board_cards\" with Board ID \"688725dad59c015ce052eecf\", \"limit\" of 100, and no \"before\" parameter. Expect the number of The Fetched Cards to be 100.",
            "- Test The Function \"fetch_board_cards\" with Board ID \"688725dad59c015ce052eecf\", \"limit\" of 100, and \"before\" set to \"688725fdf26b3c50430cae23\". Expect the number of The Fetched Cards to be 50.",
            "- Test The Function \"fetch_board_cards\" with the following flow:\n  - Step 1: Test The Function \"fetch_board_cards\" with Board ID \"688725dad59c015ce052eecf\", \"limit\" of 100, and \"before\" set to \"688725dce452b309c904aac4\" (:= apiResult)\n  - Step 2: Out of `apiResult`, retrieve the card that has property \"id\" equal to \"688725db990240b77167efef\" (:= card)\n  - Step 3: From array `card[\"attachments\"]`, retrieve the attachment object that has property \"name\" equal to \"devrev cover\" (:= attachment)\n  - Step 4: Expect `attachment[\"name\"]` to be equal to \"devrev cover\".",
            "- Test the rate limiting of The Function \"fetch_board_cards\" with the following flow:\n  - Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Invoke The Function \"fetch_board_cards\" with valid credentials and all required parameters.\n  - Expect: `status_code = 429`.\n  - Expect: `api_delay > 0` and `api_delay <= 3`. If api_delay is bigger than 3, assume the problem is that we did not calculate the api_delay correctly in The Implementation Code.\n  - Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.1.5": {
        "functional_requirement": "- Implement The Function \"download_attachment\" that uses The API to download an attachment using the endpoint \"/cards/{idCard}/attachments/{idAttachment}/download/{fileName}\".\n  - parameteres \"idCard\", \"idAttachment\", and \"fileName\" should be provided in the `event[\"input_data\"][\"global_values\"][\"idCard\"]`, `event[\"input_data\"][\"global_values\"][\"idAttachment\"]`, and `event[\"input_data\"][\"global_values\"][\"fileName\"]` respectively. All of \"idCard\", \"idAttachment\", and \"fileName\" should be required.\n  - Note: Endpoint \"/cards/{idCard}/attachments/{idAttachment}/download/{fileName}\" should be called with OAuth 1.0a authorization (oauth_consumer_key and oauth_token encoded in the Authorization header).",
        "folder_name": "conformance_tests/download_attachment_api_tests",
        "acceptance_tests": [
            "- Test The Function \"download_attachment\" with Card ID \"688725db990240b77167efef\", Attachment ID \"68c2be83c413a1889bde83df\", and fileName \"temporary-file-name.png\". Expect the call to The Function to succeed.",
            "- Test the rate limiting of The Function \"download_attachment\" with the following flow:\n  - Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Invoke The Function \"download_attachment\" with valid credentials and all required parameters.\n  - Expect: `status_code = 429`.\n  - Expect: `api_delay > 0` and `api_delay <= 3`. If api_delay is bigger than 3, assume the problem is that we did not calculate the api_delay correctly in The Implementation Code.\n  - Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.2.1.1": {
        "functional_requirement": "- Implement The Function 'get_external_domain_metadata' that generates and returns The External Domain Metadata JSON object. The External Domain Metadata JSON object should have the record type 'users'.\n  - The record type 'users' (Name: Users) should have two fields:\n    - full_name (display name: \"Full Name\", is required, type: text)\n    - username (display name: \"Username\", is required, type: text)",
        "folder_name": "conformance_tests/get_external_domain_metadata_function_tests"
    },
    "2.2.1.2": {
        "functional_requirement": "- The External Domain Metadata JSON object should include the record type 'cards', while preserving any existing record types.\n  - The record type 'cards' (Name: Cards) should have the following fields:\n    - name (display name: \"Name\", is required, type: text)\n    - url (display name: \"URL\", is required, type: text)\n    - description (display name: \"Description\", is required, type: rich text)\n    - id_members (display name: \"ID Members\", is required, type: reference)\n      - Field id_members refers to the record type \"#record:users\".\n      - Type of field id_members is an array with max_length 50.",
        "folder_name": "conformance_tests/external_domain_metadata_cards_record_type_tests"
    },
    "2.2.2.1": {
        "functional_requirement": "- Implement The Function that generates and returns The Initial Domain Mapping JSON object. The Initial Domain Mapping JSON object should have record_type_mappings \"users\".\n  - The record_type_mappings \"users\" should have the following properties:\n    - Default mapping should map each external user to a \"devu\" user object.\n    - There should be a single \"possible_record_type_mappings\" element, specifying:\n      - The mapping is one-way (reverse is false, forward is true).\n      - There should be no custom fields in the mapping.\n    - The following The Stock Field Mapping Fields should be mapped using The External Transformation Method:\n      - field \"full_name\" should be mapped to \"full_name\".\n      - field \"username\" should be mapped to \"display_name\".",
        "folder_name": "conformance_tests/initial_domain_mapping_generation_tests"
    },
    "2.2.2.2": {
        "functional_requirement": "- The Initial Domain Mapping JSON object should have record_type_mappings \"cards\", while preserving any existing mappings.\n  - The record_type_mappings \"cards\" should have the following properties:\n    - Default mapping should map each external card to a \"issue\" object.\n    - There should be a single \"possible_record_type_mappings\" element, specifying:\n      - The mapping is one-way (reverse is false, forward is true)\n      - There should be no custom fields in the mapping.\n    - The following The Stock Field Mapping Fields should be mapped using The External Transformation Method:\n      - field \"name\" should be mapped to \"title\"\n      - field \"url\" should be mapped to \"item_url_field\"\n      - field \"description\" should be mapped to \"body\" (rich text)\n      - field \"id_members\" should be mapped to \"owned_by_ids\" (use directly)\n    - The following The Stock Field Mapping Fields should be mapped using The Fixed Transformation Method:\n      - field \"priority\" should contain fixed value \"P2\"\n      - field \"stage\" should contain fixed value \"triage\"\n    - The following The Stock Field Mapping Fields should be mapped using The DevRev Record Transformation Method:\n      - field \"applies_to_part_id\" should refer to the \"product\" object type",
        "folder_name": "conformance_tests/initial_domain_mapping_cards_record_type_tests"
    },
    "2.3.1": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_EXTERNAL_SYNC_UNITS_START\", The Extraction Function should implement the \"external sync units extraction\" part of the extraction workflow as described in the resource `[resource]external-sync-units-extraction.mdx`:\n  - Retrieve The Fetched Boards\n  - Push The Fetched Boards as external sync units using the following mapping from the fields in The Fetched Boards to the fields in The External Sync Units:\n    - \"id\" from The Fetched Boards should be mapped to \"id\" in The External Sync Units\n    - \"name\" from The Fetched Boards should be mapped to \"name\" in The External Sync Units\n    - \"desc\" from The Fetched Boards should be mapped to \"description\" in The External Sync Units\n    - \"item_type\" should have a fixed value of \"cards\"",
        "folder_name": "conformance_tests/extraction_external_sync_units_start_tests",
        "acceptance_tests": [
            "- Test The Extraction Function using the resource `[resource]trello_external_sync_unit_check.json`.\n  - Expect The Callback Server to receive *a single* event with \"event_type\" \"EXTRACTION_EXTERNAL_SYNC_UNITS_DONE\".",
            "- When the input event is \"EXTRACTION_EXTERNAL_SYNC_UNITS_START\", the Extraction Function must handle rate limiting using the following test flow:\n  - Step 1: Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Step 2: Invoke The Extraction Function using the resource `[resource]trello_external_sync_unit_check.json`.\n    - Expect The Callback Server to receive *a single* event with \"event_type\" \"EXTRACTION_EXTERNAL_SYNC_UNITS_ERROR\".\n  - Step 3: Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.3.2": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_METADATA_START\" The Extraction Function should implement the \"metadata extraction\" part of the extraction workflow as described in the resource `[resource]metadata-extraction.md`. Please note that The External Domain Metadata JSON should not be normalized when pushed to the repository.",
        "folder_name": "conformance_tests/extraction_metadata_start_event_tests"
    },
    "2.3.3": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_DATA_START\" or \"EXTRACTION_DATA_CONTINUE\" The Extraction Function should push the 'users' data. To push the 'users' data, it should:\n  - If `TheExtractionStateObject[\"users\"][\"completed\"]=false`:\n    - Fetch The Fetched Users\n    - Push The Fetched Users to the repository designated for 'users' data.\n    - Set `TheExtractionStateObject[\"users\"][\"completed\"]=true`",
        "folder_name": "conformance_tests/extraction_users_data_event_tests",
        "acceptance_tests": [
            "- Test The Extraction Function using the resource `[resource]data_extraction_test.json`.\n  - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n  - Let `artifact_array = <event_from_callback_server>[\"event_data\"][\"artifacts\"]` (array of objects).\n    - Expect `len(artifact_array) > 0`.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"users\" (`:= users_artifact`) and `users_artifact[\"item_count\"]=9`.\n    - Note: If `users_artifact[\"item_count\"] < 9`, this indicates that not all the users data was extracted.",
            "- When the input event is \"EXTRACTION_DATA_START\", the Extraction Function must handle rate limiting using the following test flow:\n  - Step 1: Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Step 2: Invoke The Extraction Function using the resource `[resource]data_extraction_test.json`.\n    - Expect The Callback Server to receive *a single* event with \"event_type\" \"EXTRACTION_DATA_DELAY\".\n  - Step 3: Make a POST request to \"http://localhost:8004/end_rate_limiting\".",
            "- Validate The Normalization Function with the chef-cli tool (The Chef CLI) for the \"users\" record type:\n  - Firstly, invoke The Extraction Function using the resource `[resource]data_extraction_test.json`.\n  - Then, validate The Normalization Function with the chef-cli tool (The Chef CLI) using the command \"chef-cli validate-data -m <The External Domain Metadata JSON object file> -r users\":\n    - To invoke the function that returns The External Domain Metadata JSON object, send the event `[resource]external_domain_metadata_event_payload.json` to The Snap-In server.\n    - The External Domain Metadata JSON object should then be stored in temporary file and provided as path to the validation of The Normalization Function.\n    - The Chef CLI reads the extracted file (The Extracted File) from stdin.\n    - The Extracted File is inside folder provided in the environment variable \"EXTRACTED_FILES_FOLDER_PATH\". To retrieve the relevant file name, command `ls EXTRACTED_FILES_FOLDER_PATH | grep extractor_users | sort -r | head -n 1` should be executed. The test should always fail if The Extracted File is not present.\n    - Please note that the expected behaviour is that only after the invocation of The Extraction Function, the folder provided in the environment variable \"EXTRACTED_FILES_FOLDER_PATH\" should exist. The test should always fail if before the execution of The Chef CLI, the folder \"EXTRACTED_FILES_FOLDER_PATH\" does not exist or if The Extracted File is not found.\n    - The path to The Chef CLI executable is provided in the environment variable `CHEF_CLI_PATH`.\n    - For the validation of The Normalization Function to be successful The Chef CLI must return an empty output. The implementation of The Extraction Function directly infuences the output of The Chef CLI.\n    - The stdout and stderr of The Chef CLI *must* be printed to the console.\n    - The test should always fail if The Chef CLI is not available."
        ]
    },
    "2.3.4": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_DATA_START\" or \"EXTRACTION_DATA_CONTINUE\" The Extraction Function should push the 'cards' and 'users' data. To push the 'cards' data, it should:\n  - If `TheExtractionStateObject[\"cards\"][\"completed\"]=false`:\n    - While Fetching The Fetched Cards using pagination (The Cards Iteration):\n      - Push The Fetched Cards of the current page to the repository designated for 'cards' data (`:= cards_response`)\n      - Update `TheExtractionStateObject[\"cards\"][\"before\"]=cards_response[0][\"id\"]`\n    - Set `TheExtractionStateObject[\"cards\"][\"completed\"]=true`, `TheExtractionStateObject[\"cards\"][\"before\"]=\"\"`.",
        "folder_name": "conformance_tests/extraction_cards_data_event_tests",
        "acceptance_tests": [
            "- Test The Extraction Function using the resource `[resource]data_extraction_test.json`.\n  - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n  - Let `artifact_array = <event_from_callback_server>[\"event_data\"][\"artifacts\"]` (array of objects).\n    - Expect `len(artifact_array) > 0`.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"cards\" (`:= cards_artifact`) and `cards_artifact[\"item_count\"]=150`.\n    - Note: If `cards_artifact[\"item_count\"] < 150`, this indicates that not all the cards data was extracted.",
            "- Test The Extraction Function using the resource `[resource]data_extraction_continue_test.json`.\n  - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n  - Let `artifact_array = <event_from_callback_server>[\"event_data\"][\"artifacts\"]` (array of objects).\n    - Expect `len(artifact_array) > 0`.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"cards\" (`:= cards_artifact`) and `cards_artifact[\"item_count\"]=150`.\n    - Note: If `cards_artifact[\"item_count\"] < 150`, this indicates that not all the cards data was extracted.",
            "- When the input event is \"EXTRACTION_DATA_START\", the Extraction Function must handle rate limiting using the following test flow:\n  - Step 1: Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Step 2: Invoke The Extraction Function using the resource `[resource]data_extraction_test.json`.\n    - Expect The Callback Server to receive *a single* event with \"event_type\" \"EXTRACTION_DATA_DELAY\".\n  - Step 3: Make a POST request to \"http://localhost:8004/end_rate_limiting\".",
            "- Validate The Normalization Function with the chef-cli tool (The Chef CLI) for the \"cards\" record type:\n  - Firstly, invoke The Extraction Function using the resource `[resource]data_extraction_test.json`.\n  - Then, validate The Normalization Function with the chef-cli tool (The Chef CLI) using the command \"chef-cli validate-data -m <The External Domain Metadata JSON object file> -r cards\":\n    - To invoke the function that returns The External Domain Metadata JSON object, send the event `[resource]external_domain_metadata_event_payload.json` to The Snap-In server.\n    - The External Domain Metadata JSON object should then be stored in temporary file and provided as path to the validation of The Normalization Function.\n    - The Chef CLI reads the extracted file (The Extracted File) from stdin.\n    - The Extracted File is inside folder provided in the environment variable \"EXTRACTED_FILES_FOLDER_PATH\". To retrieve the relevant file name, command `ls EXTRACTED_FILES_FOLDER_PATH | grep extractor_cards | sort -r | head -n 1` should be executed. The test should always fail if The Extracted File is not present.\n    - Please note that the expected behaviour is that only after the invocation of The Extraction Function, the folder provided in the environment variable \"EXTRACTED_FILES_FOLDER_PATH\" should exist. The test should always fail if before the execution of The Chef CLI, the folder \"EXTRACTED_FILES_FOLDER_PATH\" does not exist or if The Extracted File is not found.\n    - The path to The Chef CLI executable is provided in the environment variable `CHEF_CLI_PATH`.\n    - For the validation of The Normalization Function to be successful The Chef CLI must return an empty output. The implementation of The Extraction Function directly infuences the output of The Chef CLI.\n    - The stdout and stderr of The Chef CLI *must* be printed to the console.\n    - The test should always fail if The Chef CLI is not available."
        ]
    },
    "2.3.5": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_DATA_START\" or \"EXTRACTION_DATA_CONTINUE\" The Extraction Function should push the 'attachments', 'cards' and 'users' data. To push the 'attachments' data, it should:\n  - If `TheExtractionStateObject[\"cards\"][\"completed\"]=false`:\n    - Inside every iteration of the Cards Iteration:\n      - Extract The Fetched Attachments from The Fetched Cards.\n      - Push The Fetched Attachments to the repository designated for 'attachments' data.\n    - Set `TheExtractionStateObject[\"attachments\"][\"completed\"]=true`\n  - Note: Refer to the resource `[resource]attachment_normalization.md` on attachment normalization.\n  - Note: Here's how to normalize \"url\" field for 'attachments' data:\n    - if field \"url\" from The Fetched Attachment object starts with \"https://trello.com\": construct the \"url\" field using the following format: f\"https://api.trello.com/1/cards/{idCard}/attachments/{idAttachment}/download/{fileName}\".\n    - else: set the \"url\" field to the original \"url\" field.",
        "folder_name": "conformance_tests/extraction_attachments_data_event_tests",
        "acceptance_tests": [
            "- Test The Extraction Function using the resource `[resource]data_extraction_test.json`.\n  - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n  - Let `artifact_array = <event_from_callback_server>[\"event_data\"][\"artifacts\"]` (array of objects).\n    - Expect `len(artifact_array) > 0`.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"attachments\" (`:= attachments_artifact`) and `attachments_artifact[\"item_count\"]=2`.\n    - Note: If `attachments_artifact[\"item_count\"] < 2`, this indicates that not all the attachments data was extracted."
        ]
    },
    "2.3.6": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_ATTACHMENTS_START\" or \"EXTRACTION_ATTACHMENTS_CONTINUE\" The Extraction Function should implement attachment extraction as described in the resource `[resource]attachments-extraction.md`.\n  - Note: Streaming the attachments *MUST* be authenticated using OAuth 1.0a authorization (oauth_consumer_key and oauth_token encoded in the Authorization header).",
        "folder_name": "conformance_tests/extraction_attachments_oauth_authentication_tests",
        "acceptance_tests": [
            "- Test The Extraction Function with the following flow (The Attachment Test Flow):\n  - Step 1: Invoke The Extraction Function using the resource `[resource]data_extraction_test.json`.\n    - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n  - Step 2: Invoke The Extraction Function using the resource `[resource]attachments_extraction_test.json`.\n    - Expect The Callback Server to receive from DevRev a **single** event (`:= event_from_callback_server`) with \"event_type\" that equals \"EXTRACTION_ATTACHMENTS_DONE\".\n    - Expect `event_from_callback_server[\"event_data\"][\"artifacts\"]` to be an array. Expect this array to not be empty. Expect this array to have length 1.\n    - Let `artifact_object = event_from_callback_server[\"event_data\"][\"artifacts\"][0]`.\n      - Expect `artifact_object[\"item_type\"] = \"ssor_attachment\"` and `artifact_object[\"item_count\"] = 2`.\n      - Make a GET request to \"http://localhost:8003/is_uploaded/{artifact_object['id']}\". Expect response code to be equal to 200.\n  - Note: The Attachment Test Flow should be executed within a single test.",
            "- Test The Extraction Function using the resource `[resource]attachments_extraction_continue_test.json`.\n  - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_ATTACHMENTS_DONE\".",
            "- When the input event is \"EXTRACTION_ATTACHMENTS_START\", the Extraction Function must handle rate limiting using the following test flow:\n  - Step 1: Make a POST request to \"http://localhost:8004/start_rate_limiting\" with body `{ \"test_name\": <identifyer of the test>}`.\n  - Step 2: Invoke The Extraction Function using the resource `[resource]attachments_extraction_test.json`.\n    - Expect The Callback Server to receive *a single* event with \"event_type\" \"EXTRACTION_ATTACHMENTS_DONE\".\n  - Step 3: Make a POST request to \"http://localhost:8004/end_rate_limiting\"."
        ]
    },
    "2.3.7": {
        "functional_requirement": "- If \"event_type\" equals \"EXTRACTION_DATA_START\", The Extraction Function should support incremental data synchronization as described in the resource `[resource]incremental_mode.md`.\n  - Incremental mode should only work for the \"cards\" and their corresponding \"attachments\" data. If `event[\"payload\"][\"event_context\"][\"mode\"]=SyncMode.INCREMENTAL`, set:\n    - `TheExtractionStateObject[\"cards\"][\"modifiedSince\"]=adapter.state.lastSuccessfulSyncStarted`\n    - `TheExtractionStateObject[\"cards\"][\"completed\"]=false`\n    - `TheExtractionStateObject[\"attachments\"][\"completed\"]=false`\n  - Based on the field \"dateLastActivity\" (ISO 8601 Extended Format with timezone), you should client-side filter only the The Fetched Cards that have been updated after the time of the last successful sync.\n  - Note: The API *does not* support filtering by \"dateLastActivity\" server-side.\n  - Note: In incremental mode, you should push only the filtered cards and their corresponding attachments to the DevRev servers.",
        "folder_name": "conformance_tests/extraction_data_start_incremental_mode_tests",
        "acceptance_tests": [
            "- Validate the incremental mode with the following flow:\n  - Step 1:\n    - Execute request `curl -X POST \"http://localhost:8003/external-worker.update-last-successful-sync/<sync_unit_id>\" -H \"Content-Type: application/json\" -d '{\"snap_in_version_id\":\"test-version-id\",\"extend_state\":{\"users\":{\"completed\":true},\"cards\":{\"completed\":true},\"attachments\":{\"completed\":true}}}'`, where `<sync_unit_id>` is `event[\"payload\"][\"event_context\"][\"sync_unit_id\"]` in the resource `[resource]data_extraction_test.json`.\n  - Step 2:\n    - Execute request `curl --request PUT --url 'https://api.trello.com/1/cards/688725fd3e26ebcf364bff4a?key=<TRELLO_API_KEY>&token=<TRELLO_TOKEN>&name=\"Card50-<uuid>\"' --header 'Accept: application/json'` (replace <TRELLO_API_KEY>, <TRELLO_TOKEN> and <uuid> with the actual values).\n    - Expect the request to succeed.\n  - Step 3:\n    - Invoke The Extraction Function using the resource `[resource]data_extraction_incremental_test.json`.\n    - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n    - Let `artifact_array = <event_from_callback_server>[\"event_data\"][\"artifacts\"]` (array of objects).\n    - Expect `artifact_array` to not be empty array.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"cards\" (`:= cards_artifact`). Expect `cards_artifact[\"item_count\"]=1`.\n    - Expect that there is no element in `artifact_array` with \"item_type\" equal to \"attachments\". If there is, this indicates that the attachments data was pushed to the DevRev servers, which is wrong.\n    - Expect that there is no element in `artifact_array` with \"item_type\" equal to \"users\". If there is, this indicates that the users data was pushed to the DevRev servers, which is wrong.",
            "- Validate the incremental mode with the following flow:\n  - Step 1:\n    - Execute request `curl -X POST \"http://localhost:8003/external-worker.update-last-successful-sync/<sync_unit_id>\" -H \"Content-Type: application/json\" -d '{\"snap_in_version_id\":\"test-version-id\",\"extend_state\":{\"users\":{\"completed\":true},\"cards\":{\"completed\":true},\"attachments\":{\"completed\":true}}}'`, where `<sync_unit_id>` is `event[\"payload\"][\"event_context\"][\"sync_unit_id\"]` in the resource `[resource]data_extraction_test.json`.\n  - Step 2:\n    - Execute request `curl --request PUT --url 'https://api.trello.com/1/cards/688725db990240b77167efef?key=<TRELLO_API_KEY>&token=<TRELLO_TOKEN>&name=\"Card1-<uuid>\"' --header 'Accept: application/json'` (replace <TRELLO_API_KEY>, <TRELLO_TOKEN> and <uuid> with the actual values).\n    - Expect the request to succeed.\n  - Step 3:\n    - Invoke The Extraction Function using the resource `[resource]data_extraction_incremental_test.json`.\n    - Expect The Callback Server to receive from DevRev a **single** event with \"event_type\" that equals \"EXTRACTION_DATA_DONE\".\n    - Let `artifact_array = <event_from_callback_server>[\"event_data\"][\"artifacts\"]` (array of objects).\n    - Expect `artifact_array` to not be empty array.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"cards\" (`:= cards_artifact`). Expect `cards_artifact[\"item_count\"]=1`.\n    - Out of `artifact_array`, expect one of the elements to have \"item_type\" equal to \"attachments\" (`:= attachments_artifact`). Expect `attachments_artifact[\"item_count\"]=2`.\n    - Expect that there is no element in `artifact_array` with \"item_type\" equal to \"users\". If there is, this indicates that the users data was pushed to the DevRev servers, which is wrong."
        ]
    }
}